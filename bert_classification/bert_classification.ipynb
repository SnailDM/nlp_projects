{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e3654b-2a79-4f09-9e57-25b2ad103dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.optim import optimizer\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
    "from torch.nn import CrossEntropyLoss,BCEWithLogitsLoss\n",
    "from tqdm import tqdm_notebook, trange\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification\n",
    "from pytorch_pretrained_bert.optimization import BertAdam, WarmupLinearSchedule\n",
    "from sklearn.metrics import precision_recall_curve,classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8c20572-92b8-4463-acb8-908ecce4ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_RATIO = 0.9   #训练和验证集的比例\n",
    "#MAX_SEQ_LEN = 50\n",
    "BATCH_SIZE = 64\n",
    "SEED = 0\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7330017-8f93-4b22-b956-76086ab1ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#早停法\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b18c30b-ee72-42f1-855e-9e267d40e9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#标签平滑\n",
    "class LabelSmoothing(nn.Module):\n",
    "    def __init__(self, size, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(size_average=False)\n",
    "        #self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing#if i=y的公式\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "    \n",
    "    def forward(self, x, target):\n",
    "        \"\"\"\n",
    "        x表示输入 (N，M)N个样本，M表示总类数，每一个类的概率log P\n",
    "        target表示label（M，）\n",
    "        \"\"\"\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()#先深复制过来\n",
    "        #print true_dist\n",
    "        true_dist.fill_(self.smoothing / (self.size - 1))#otherwise的公式\n",
    "        #print true_dist\n",
    "        #变成one-hot编码，1表示按列填充，\n",
    "        #target.data.unsqueeze(1)表示索引,confidence表示填充的数字\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        self.true_dist = true_dist\n",
    "\n",
    "        return self.criterion(x, Variable(true_dist, requires_grad=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e832934f-6e28-4303-b319-4b63002422c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据处理类\n",
    "class DataPrecessForSingleSentence(object):\n",
    "    \"\"\"\n",
    "    对文本进行处理\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bert_tokenizer, max_workers=10):\n",
    "        \"\"\"\n",
    "        bert_tokenizer :分词器\n",
    "        dataset        :包含列名为'text'与'label'的pandas dataframe\n",
    "        \"\"\"\n",
    "        self.bert_tokenizer = bert_tokenizer\n",
    "        # 创建多线程池\n",
    "        self.pool = ThreadPoolExecutor(max_workers=max_workers)\n",
    "        # 获取文本与标签\n",
    "\n",
    "    def get_input(self, dataset, max_seq_len=50):\n",
    "        \"\"\"\n",
    "        通过多线程（因为notebook中多进程使用存在一些问题）的方式对输入文本进行分词、ID化、截断、填充等流程得到最终的可用于模型输入的序列。\n",
    "        \n",
    "        入参:\n",
    "            dataset     : pandas的dataframe格式，包含两列，第一列为文本，第二列为标签。标签取值为{0,1}，其中0表示负样本，1代表正样本。\n",
    "            max_seq_len : 目标序列长度，该值需要预先对文本长度进行分别得到，可以设置为小于等于512（BERT的最长文本序列长度为512）的整数。\n",
    "        \n",
    "        出参:\n",
    "            seq         : 在入参seq的头尾分别拼接了'CLS'与'SEP'符号，如果长度仍小于max_seq_len，则使用0在尾部进行了填充。\n",
    "            seq_mask    : 只包含0、1且长度等于seq的序列，用于表征seq中的符号是否是有意义的，如果seq序列对应位上为填充符号，\n",
    "                          那么取值为1，否则为0。\n",
    "            seq_segment : shape等于seq，因为是单句，所以取值都为0。\n",
    "            labels      : 标签取值为{0,1}，其中0表示负样本，1代表正样本。   \n",
    "        \"\"\"\n",
    "        sentences = dataset.iloc[:, 0].tolist()\n",
    "        labels = dataset.iloc[:, 1].tolist()\n",
    "        # 切词\n",
    "        tokens_seq = list(\n",
    "            self.pool.map(self.bert_tokenizer.tokenize, sentences))\n",
    "        # 获取定长序列及其mask\n",
    "        result = list(\n",
    "            self.pool.map(self.trunate_and_pad, tokens_seq,\n",
    "                          [max_seq_len] * len(tokens_seq)))\n",
    "        seqs = [i[0] for i in result]\n",
    "        seq_masks = [i[1] for i in result]\n",
    "        seq_segments = [i[2] for i in result]\n",
    "        return seqs, seq_masks, seq_segments, labels\n",
    "\n",
    "    def trunate_and_pad(self, seq, max_seq_len):\n",
    "        \"\"\"\n",
    "        1. 因为本类处理的是单句序列，按照BERT中的序列处理方式，需要在输入序列头尾分别拼接特殊字符'CLS'与'SEP'，\n",
    "           因此不包含两个特殊字符的序列长度应该小于等于max_seq_len-2，如果序列长度大于该值需要那么进行截断。\n",
    "        2. 对输入的序列 最终形成['CLS',seq,'SEP']的序列，该序列的长度如果小于max_seq_len，那么使用0进行填充。\n",
    "        \n",
    "        入参: \n",
    "            seq         : 输入序列，在本处其为单个句子。\n",
    "            max_seq_len : 拼接'CLS'与'SEP'这两个特殊字符后的序列长度\n",
    "        \n",
    "        出参:\n",
    "            seq         : 在入参seq的头尾分别拼接了'CLS'与'SEP'符号，如果长度仍小于max_seq_len，则使用0在尾部进行了填充。\n",
    "            seq_mask    : 只包含0、1且长度等于seq的序列，用于表征seq中的符号是否是有意义的，如果seq序列对应位上为填充符号，\n",
    "                          那么取值为1，否则为0。\n",
    "            seq_segment : shape等于seq，因为是单句，所以取值都为0。\n",
    "           \n",
    "        \"\"\"\n",
    "        # 对超长序列进行截断\n",
    "        if len(seq) > (max_seq_len - 2):\n",
    "            seq = seq[0:(max_seq_len - 2)]\n",
    "        # 分别在首尾拼接特殊符号\n",
    "        seq = ['[CLS]'] + seq + ['[SEP]']\n",
    "        # ID化\n",
    "        seq = self.bert_tokenizer.convert_tokens_to_ids(seq)\n",
    "        # 根据max_seq_len与seq的长度产生填充序列\n",
    "        padding = [0] * (max_seq_len - len(seq))\n",
    "        # 创建seq_mask\n",
    "        seq_mask = [1] * len(seq) + padding\n",
    "        # 创建seq_segment\n",
    "        seq_segment = [0] * len(seq) + padding\n",
    "        # 对seq拼接填充序列\n",
    "        seq += padding\n",
    "        assert len(seq) == max_seq_len\n",
    "        assert len(seq_mask) == max_seq_len\n",
    "        assert len(seq_segment) == max_seq_len\n",
    "        return seq, seq_mask, seq_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "996a0fc1-d8cb-464f-a9c2-cf37ab0655c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>马晓旭意外受伤让国奥警惕 无奈大雨格外青睐殷家军记者傅亚雨沈阳报道 来到沈阳，国奥队依然没有...</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>商瑞华首战复仇心切 中国玫瑰要用美国方式攻克瑞典多曼来了，瑞典来了，商瑞华首战求3分的信心也...</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>冠军球队迎新欢乐派对 黄旭获大奖张军赢下PK赛新浪体育讯12月27日晚，“冠军高尔夫球队迎新...</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>辽足签约危机引注册难关 高层威逼利诱合同笑里藏刀新浪体育讯2月24日，辽足爆发了集体拒签风波...</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>揭秘谢亚龙被带走：总局电话骗局 复制南杨轨迹体坛周报特约记者张锐北京报道  谢亚龙已经被公安...</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  马晓旭意外受伤让国奥警惕 无奈大雨格外青睐殷家军记者傅亚雨沈阳报道 来到沈阳，国奥队依然没有...    体育\n",
       "1  商瑞华首战复仇心切 中国玫瑰要用美国方式攻克瑞典多曼来了，瑞典来了，商瑞华首战求3分的信心也...    体育\n",
       "2  冠军球队迎新欢乐派对 黄旭获大奖张军赢下PK赛新浪体育讯12月27日晚，“冠军高尔夫球队迎新...    体育\n",
       "3  辽足签约危机引注册难关 高层威逼利诱合同笑里藏刀新浪体育讯2月24日，辽足爆发了集体拒签风波...    体育\n",
       "4  揭秘谢亚龙被带走：总局电话骗局 复制南杨轨迹体坛周报特约记者张锐北京报道  谢亚龙已经被公安...    体育"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_table('./data/cls_datasets/cnews.train.txt', encoding='utf-8', names=['label', 'text'])\n",
    "train = train[['text', 'label']]\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfb286da-3ccd-4fb4-9045-5ac804951618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "885727c8-b5f1-4647-8660-8ab8d3e9f5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>一血万杰中是存在着各种种属性的，属性之间也是有着相互克制的关系存在，不过这个属性比较复杂所以...</td>\n",
       "      <td>游戏</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>崩坏3的新版本来到了3.8版本，在这个版本中也是更新了很多的武器，而随着武器的增加玩家们也是...</td>\n",
       "      <td>游戏</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>炉石传说的新英雄也是增加了不少的哦，而想要吃鸡的话一定是要选一个后期类型的橘色，之前是奈法利...</td>\n",
       "      <td>游戏</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>跑跑卡丁车手游中新出的焕新计划活动是非常有意思的，很多小伙伴们也是期待很久的活动了，那么跑跑...</td>\n",
       "      <td>游戏</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>濡沫江湖作为一款江湖类型的游戏，玩家肯定是要选择一个冷兵器作为自己的主武器的，很多玩家都是选...</td>\n",
       "      <td>游戏</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label  label_id\n",
       "0  一血万杰中是存在着各种种属性的，属性之间也是有着相互克制的关系存在，不过这个属性比较复杂所以...    游戏         7\n",
       "1  崩坏3的新版本来到了3.8版本，在这个版本中也是更新了很多的武器，而随着武器的增加玩家们也是...    游戏         7\n",
       "2  炉石传说的新英雄也是增加了不少的哦，而想要吃鸡的话一定是要选一个后期类型的橘色，之前是奈法利...    游戏         7\n",
       "3  跑跑卡丁车手游中新出的焕新计划活动是非常有意思的，很多小伙伴们也是期待很久的活动了，那么跑跑...    游戏         7\n",
       "4  濡沫江湖作为一款江湖类型的游戏，玩家肯定是要选择一个冷兵器作为自己的主武器的，很多玩家都是选...    游戏         7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train.label.tolist())\n",
    "train['label_id'] = le.transform(train.label.tolist())\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4be800ad-2db0-4bc4-ac7d-3cd9d3eca9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeldata = train.groupby(['label', 'label_id']).count().reset_index()\n",
    "num_labels = labeldata.shape[0]\n",
    "labeldata.to_excel('./data/cls_datasets/train_labels.xlsx', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27ad1ede-c8c7-4a9a-be05-43444f3ffef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data= train[['text', 'label_id']] \n",
    "train, valid = train_test_split(train_data, train_size=SPLIT_RATIO, random_state=SEED)\n",
    "train_labels = train.groupby(['label_id']).count().reset_index()\n",
    "valid_labels = valid.groupby(['label_id']).count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2045088-222e-496d-9adf-f763234e0a6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>忍者学园中玩家们可以去选择一个自己喜欢的家族然后加入的，而在加入了家族以后，玩家们也是需要对...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>产业互联网时代，“云”成为企业对外输出服务的重要通道。在以腾讯云为代表的公有云获得快速发展的...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3571</th>\n",
       "      <td>明日方舟最新也是发布了公告，在明日25日需要开启一次闪断更新，这次更新的目的主要是修改BUG...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5210</th>\n",
       "      <td>杨燕认为，目前的风险在于，美国政府目前没有采取强有力的举措阻止疫情在本土扩散，是否会埋下大规...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4947</th>\n",
       "      <td>金九银十，凉爽的秋风送走了夏日的炎热，在9月25日这个特殊的日子里，上海凡斯环保技术咨询有限...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label_id\n",
       "1380  忍者学园中玩家们可以去选择一个自己喜欢的家族然后加入的，而在加入了家族以后，玩家们也是需要对...         7\n",
       "1573  产业互联网时代，“云”成为企业对外输出服务的重要通道。在以腾讯云为代表的公有云获得快速发展的...         8\n",
       "3571  明日方舟最新也是发布了公告，在明日25日需要开启一次闪断更新，这次更新的目的主要是修改BUG...         7\n",
       "5210  杨燕认为，目前的风险在于，美国政府目前没有采取强有力的举措阻止疫情在本土扩散，是否会埋下大规...         9\n",
       "4947  金九银十，凉爽的秋风送走了夏日的炎热，在9月25日这个特殊的日子里，上海凡斯环保技术咨询有限...         2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78724f27-c53c-4f51-a37c-02280a97f5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分词工具\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('./pretrained_models/chinese_wwm_ext_pytorch/', do_lower_case=False)\n",
    "# 类初始化\n",
    "processor = DataPrecessForSingleSentence(bert_tokenizer= bert_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59cc44c4-66d9-429c-9e36-7d25cb5a60d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 产生训练集输入数据\n",
    "seqs, seq_masks, seq_segments, labels = processor.get_input(\n",
    "    dataset=train)\n",
    "# 转换为torch tensor\n",
    "t_seqs = torch.tensor(seqs, dtype=torch.long)\n",
    "t_seq_masks = torch.tensor(seq_masks, dtype = torch.long)\n",
    "t_seq_segments = torch.tensor(seq_segments, dtype = torch.long)\n",
    "t_labels = torch.tensor(labels, dtype = torch.long)\n",
    "\n",
    "train_data = TensorDataset(t_seqs, t_seq_masks, t_seq_segments, t_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloder = DataLoader(dataset= train_data, sampler= train_sampler,batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e206dd7-c2b5-4467-9f24-7f39aece0b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 产生验证集输入数据\n",
    "seqs, seq_masks, seq_segments, labels = processor.get_input(\n",
    "    dataset=valid)\n",
    "# 转换为torch tensor\n",
    "t_seqs = torch.tensor(seqs, dtype=torch.long)\n",
    "t_seq_masks = torch.tensor(seq_masks, dtype = torch.long)\n",
    "t_seq_segments = torch.tensor(seq_segments, dtype = torch.long)\n",
    "t_labels = torch.tensor(labels, dtype = torch.long)\n",
    "\n",
    "valid_data = TensorDataset(t_seqs, t_seq_masks, t_seq_segments, t_labels)\n",
    "valid_sampler = RandomSampler(valid_data)\n",
    "valid_dataloder = DataLoader(dataset= valid_data, sampler= valid_sampler,batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c309ec22-8e7d-4ee8-80ca-3a0057626ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('./pretrained_models/chinese_wwm_ext_pytorch/', num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b6faadf-1802-419a-936b-b3f27eca16ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cpu')\n",
    "device = torch.device('cuda')  #gpu版本\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7928f2f6-1536-49ee-8239-41e2b2047c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.7/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    }
   ],
   "source": [
    "# 待优化的参数\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params':[p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay':0.01},\n",
    "    {'params':[p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay':0.0}\n",
    "]\n",
    "\n",
    "steps = len(train_dataloder) * EPOCHS\n",
    "optimizer = BertAdam(optimizer_grouped_parameters, lr=2e-05, warmup= 0.1 , t_total= steps)\n",
    "loss_function = LabelSmoothing(num_labels, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cec0076f-7d2a-4400-a663-50bb47817159",
   "metadata": {},
   "outputs": [],
   "source": [
    "#存储loss\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "avg_train_losses = []\n",
    "avg_valid_losses = []\n",
    "patience = 20\n",
    "early_stopping = EarlyStopping(patience=patience, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76ad4860-bc44-497c-9412-0cc2f8302d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]/root/miniconda3/envs/myconda/lib/python3.7/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36dfade7546d4a54ac5c2d03ec83e5c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119.252502"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.7/site-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
      "  next_m.mul_(beta1).add_(1 - beta1, grad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.6814809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.7/site-packages/ipykernel_launcher.py:34: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b44b66dd4534ec3b1fc2db668bb0c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=12.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss:44.165707, valid_loss:17.342448\n",
      "Validation loss decreased (inf --> 17.342448).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 1/10 [02:48<25:17, 168.64s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6feff0183b504abbaa4399a6ff487c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.438083\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405235cd2bec4410850971520c329aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=12.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss:14.314930, valid_loss:14.664161\n",
      "Validation loss decreased (17.342448 --> 14.664161).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 2/10 [05:36<22:27, 168.38s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a7cb33ce59b48c8bb64cacb54831ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.8124375\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eedb93204b3c457da579d3e9884f9265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=12.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss:8.963892, valid_loss:13.503767\n",
      "Validation loss decreased (14.664161 --> 13.503767).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|███       | 3/10 [08:26<19:41, 168.83s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b0255b253e44436921eeccb49691e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.8383583\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b9e7cf35e448d69d04638cbbbe8b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=12.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 4/10 [11:06<16:37, 166.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss:5.020716, valid_loss:14.994694\n",
      "EarlyStopping counter: 1 out of 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04348eca1b4e4c1e859c6b85893e487a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7391528\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300d3991e99b42df9ec9f35b406af41a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=12.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|█████     | 5/10 [13:47<13:42, 164.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss:3.051428, valid_loss:13.925060\n",
      "EarlyStopping counter: 2 out of 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1396c8430b7c4921bb4058fe26799001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.248351\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b66dee5caeb40c2b5f933326a6aa480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=12.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 6/10 [16:27<10:53, 163.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss:1.780845, valid_loss:16.850296\n",
      "EarlyStopping counter: 3 out of 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58bbc3d38b6d466d8f1f54a53ed62f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2060300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f28de729aede4143a707eeb184881d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=12.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████   | 7/10 [19:07<08:07, 162.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss:1.189606, valid_loss:15.955579\n",
      "EarlyStopping counter: 4 out of 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "496e43e73e244ccd9d11ef7ca62805f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.173467\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d5b98f883e41f8b80b29e81d4c1838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=12.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 8/10 [21:47<05:23, 161.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss:0.843451, valid_loss:16.240412\n",
      "EarlyStopping counter: 5 out of 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac7a363d2c14e69991e733d761f130e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.479741\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2904e1066ae1434082947a9c4f9c4afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=12.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████ | 9/10 [24:27<02:41, 161.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss:0.567030, valid_loss:16.217137\n",
      "EarlyStopping counter: 6 out of 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b63c7830058c4f6db310f9196a81e8f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=103.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.147810\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769181f8ffc74b489b8506bf03dd6e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=12.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 10/10 [27:07<00:00, 162.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "train_loss:0.457938, valid_loss:16.270841\n",
      "EarlyStopping counter: 7 out of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in trange(EPOCHS, desc='Epoch'):\n",
    "    \n",
    "    model.train() #训练\n",
    "    for step, batch_data in enumerate(\n",
    "            tqdm_notebook(train_dataloder, desc='Iteration')):\n",
    "        batch_data = tuple(t.to(device) for t in batch_data)\n",
    "        batch_seqs, batch_seq_masks, batch_seq_segments, batch_labels = batch_data\n",
    "        # 对标签进行onehot编码\n",
    "        one_hot = torch.zeros(batch_labels.size(0), num_labels).long().cuda()  #gpu版本\n",
    "#         one_hot = torch.zeros(batch_labels.size(0), num_labels).long()   #cpu版本\n",
    "#以下注释为gpu版本\n",
    "        one_hot_batch_labels = one_hot.scatter_(\n",
    "            dim=1,\n",
    "            index=torch.unsqueeze(batch_labels, dim=1),\n",
    "            src=torch.ones(batch_labels.size(0), num_labels).long().cuda())\n",
    "#         one_hot_batch_labels = one_hot.scatter_(\n",
    "#             dim=1,\n",
    "#             index=torch.unsqueeze(batch_labels, dim=1),\n",
    "#             src=torch.ones(batch_labels.size(0), num_labels).long())\n",
    "\n",
    "        logits = model(\n",
    "            batch_seqs, batch_seq_masks, batch_seq_segments, labels=None)\n",
    "        logits = torch.nn.functional.log_softmax(logits, dim=1)\n",
    "        #loss_function = CrossEntropyLoss()\n",
    "        loss = loss_function(logits, batch_labels)\n",
    "        loss.backward()\n",
    "        train_losses.append(loss.item())\n",
    "        print(\"\\r%f\" % loss, end='')\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    model.eval() #验证\n",
    "    for step, batch_data in enumerate(\n",
    "            tqdm_notebook(valid_dataloder, desc='Iteration')):\n",
    "        with torch.no_grad():\n",
    "            batch_data = tuple(t.to(device) for t in batch_data)\n",
    "            batch_seqs, batch_seq_masks, batch_seq_segments, batch_labels = batch_data\n",
    "            # 对标签进行onehot编码，以下注释为gpu版本\n",
    "            one_hot = torch.zeros(batch_labels.size(0), num_labels).long().cuda()\n",
    "            one_hot_batch_labels = one_hot.scatter_(\n",
    "                dim=1,\n",
    "                index=torch.unsqueeze(batch_labels, dim=1),\n",
    "                src=torch.ones(batch_labels.size(0), num_labels).long().cuda())\n",
    "#             one_hot = torch.zeros(batch_labels.size(0), num_labels).long()\n",
    "#             one_hot_batch_labels = one_hot.scatter_(\n",
    "#                 dim=1,\n",
    "#                 index=torch.unsqueeze(batch_labels, dim=1),\n",
    "#                 src=torch.ones(batch_labels.size(0), num_labels).long())\n",
    "\n",
    "            logits = model(\n",
    "                batch_seqs, batch_seq_masks, batch_seq_segments, labels=None)\n",
    "            logits = torch.nn.functional.log_softmax(logits, dim=1)\n",
    "            #loss_function = CrossEntropyLoss()\n",
    "            loss = loss_function(logits, batch_labels)\n",
    "            valid_losses.append(loss.item())\n",
    "            \n",
    "    train_loss = np.average(train_losses)\n",
    "    valid_loss = np.average(valid_losses)\n",
    "    avg_train_losses.append(train_loss)\n",
    "    avg_valid_losses.append(valid_loss)\n",
    "    print(\"train_loss:%f, valid_loss:%f\" %(train_loss, valid_loss))\n",
    "    \n",
    "    #重置训练损失和验证损失\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    \n",
    "    early_stopping(valid_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early Stopping\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f1999cc-38c7-4815-8710-6c14e2f6cdcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "fig = plt.figure(figsize=(8,6))\n",
    "plt.plot(range(1, len(avg_train_losses)+1), avg_train_losses, label='Training Loss')\n",
    "plt.plot(range(1, len(avg_valid_losses)+1), avg_valid_losses, label='Validation Loss')\n",
    "\n",
    "#find the position of lowest validation loss\n",
    "minposs = avg_valid_losses.index(min(avg_valid_losses))+1\n",
    "plt.axvline(minposs, linestyle='--', color = 'r', label='Early Stopping Checkpoint')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('loss_plot.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "220e1525-4667-4d0d-b050-4e0ed1d99a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, open(\"./checkpoints/job_fine_tuned_bert.bin\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "03e75d6f-82a5-4e8b-bea7-2eb25e5e0b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>鲍勃库西奖归谁属？ NCAA最强控卫是坎巴还是弗神新浪体育讯如今，本赛季的NCAA进入到了末...</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>麦基砍28+18+5却充满寂寞 纪录之夜他的痛阿联最懂新浪体育讯上天对每个人都是公平的，贾维...</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>黄蜂vs湖人首发：科比冲击七连胜 火箭两旧将登场新浪体育讯北京时间3月28日，NBA常规赛洛...</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>双面谢亚龙作秀终成做作 谁来为低劣行政能力埋单是谁任命了谢亚龙？谁放纵了谢亚龙？谁又该为谢亚...</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>兔年首战山西换帅后有虎胆 张学文用乔丹名言励志今晚客场挑战浙江稠州银行队，是山西汾酒男篮的兔...</td>\n",
       "      <td>体育</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  鲍勃库西奖归谁属？ NCAA最强控卫是坎巴还是弗神新浪体育讯如今，本赛季的NCAA进入到了末...    体育\n",
       "1  麦基砍28+18+5却充满寂寞 纪录之夜他的痛阿联最懂新浪体育讯上天对每个人都是公平的，贾维...    体育\n",
       "2  黄蜂vs湖人首发：科比冲击七连胜 火箭两旧将登场新浪体育讯北京时间3月28日，NBA常规赛洛...    体育\n",
       "3  双面谢亚龙作秀终成做作 谁来为低劣行政能力埋单是谁任命了谢亚龙？谁放纵了谢亚龙？谁又该为谢亚...    体育\n",
       "4  兔年首战山西换帅后有虎胆 张学文用乔丹名言励志今晚客场挑战浙江稠州银行队，是山西汾酒男篮的兔...    体育"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_table('./data/cls_datasets/cnews.test.txt', encoding='utf-8', names=['label', 'text'])\n",
    "test_data = test_data[['text', 'label']]\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc49e968-4b3a-43f1-890e-4ebdc8c0041a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>体育</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>娱乐</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>家居</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>房产</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>教育</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>时尚</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>时政</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>游戏</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>科技</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>财经</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label  label_id\n",
       "0    体育         0\n",
       "1    娱乐         1\n",
       "2    家居         2\n",
       "3    房产         3\n",
       "4    教育         4\n",
       "5    时尚         5\n",
       "6    时政         6\n",
       "7    游戏         7\n",
       "8    科技         8\n",
       "9    财经         9"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(test_data.label.tolist())\n",
    "# 标签ID化\n",
    "test_data['label_id'] = le.transform(test_data.label.tolist())\n",
    "labels_data = test_data.groupby(['label', 'label_id']).count().reset_index()\n",
    "labels_map = labels_data[['label', 'label_id']]\n",
    "labels_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ca9eb82d-0602-49d4-894c-864e74437f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.7/site-packages/ipykernel_launcher.py:17: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf12ad18489f461d81f0539364b4b359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='TEST', max=53.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      1000\n",
      "           1       0.83      0.96      0.89      1000\n",
      "           2       0.90      0.88      0.89      1000\n",
      "           3       0.88      0.71      0.79      1000\n",
      "           4       0.91      0.69      0.78      1000\n",
      "           5       0.93      0.85      0.89      1000\n",
      "           6       0.71      0.92      0.80      1000\n",
      "           7       0.97      0.91      0.94      1000\n",
      "           8       0.96      0.94      0.95      1000\n",
      "           9       0.90      0.99      0.94      1000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.89      0.88      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 转换为tensor\n",
    "test_data['label'] = le.transform(test_data.label.tolist())\n",
    "test_seqs, test_seq_masks, test_seq_segments, test_labels = processor.get_input(\n",
    "    dataset=test_data)\n",
    "test_seqs = torch.tensor(test_seqs, dtype=torch.long)\n",
    "test_seq_masks = torch.tensor(test_seq_masks, dtype = torch.long)\n",
    "test_seq_segments = torch.tensor(test_seq_segments, dtype = torch.long)\n",
    "test_labels = torch.tensor(test_labels, dtype = torch.long)\n",
    "test_data = TensorDataset(test_seqs, test_seq_masks, test_seq_segments, test_labels)\n",
    "test_dataloder = DataLoader(dataset= test_data, batch_size = 192)\n",
    "# 用于存储预测标签与真实标签\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "model.eval()\n",
    "# 预测\n",
    "with torch.no_grad():\n",
    "    for batch_data in tqdm_notebook(test_dataloder, desc = 'TEST'):\n",
    "        batch_data = tuple(t.to(device) for t in batch_data)\n",
    "        batch_seqs, batch_seq_masks, batch_seq_segments, batch_labels = batch_data        \n",
    "        logits = model(\n",
    "            batch_seqs, batch_seq_masks, batch_seq_segments, labels=None)\n",
    "        logits = logits.softmax(dim=1).argmax(dim = 1)\n",
    "        pred_labels.append(logits.detach().cpu().numpy())\n",
    "        true_labels.append(batch_labels.detach().cpu().numpy())\n",
    "# 查看各个类别的准确率和召回率\n",
    "result = classification_report(np.concatenate(true_labels), np.concatenate(pred_labels))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f1e98c31-302a-4f0a-8ca2-d36d8718d831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      1000\n",
      "           1       0.83      0.96      0.89      1000\n",
      "           2       0.90      0.88      0.89      1000\n",
      "           3       0.88      0.71      0.79      1000\n",
      "           4       0.91      0.69      0.78      1000\n",
      "           5       0.93      0.85      0.89      1000\n",
      "           6       0.71      0.92      0.80      1000\n",
      "           7       0.97      0.91      0.94      1000\n",
      "           8       0.96      0.94      0.95      1000\n",
      "           9       0.90      0.99      0.94      1000\n",
      "\n",
      "    accuracy                           0.88     10000\n",
      "   macro avg       0.89      0.88      0.88     10000\n",
      "weighted avg       0.89      0.88      0.88     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = classification_report(np.concatenate(true_labels), np.concatenate(pred_labels))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f103285e-b068-4549-9bc1-abd5a6a58740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label  label_id  precision  recall  f1_score  support\n",
      "0    体育         0       0.92    1.00      0.96   1000.0\n",
      "1    娱乐         1       0.83    0.96      0.89   1000.0\n",
      "2    家居         2       0.90    0.88      0.89   1000.0\n",
      "3    房产         3       0.88    0.71      0.79   1000.0\n",
      "4    教育         4       0.91    0.69      0.78   1000.0\n",
      "5    时尚         5       0.93    0.85      0.89   1000.0\n",
      "6    时政         6       0.71    0.92      0.80   1000.0\n",
      "7    游戏         7       0.97    0.91      0.94   1000.0\n",
      "8    科技         8       0.96    0.94      0.95   1000.0\n",
      "9    财经         9       0.90    0.99      0.94   1000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/myconda/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "def classification_report_csv(report):\n",
    "    report_data = []\n",
    "    lines = report.split('\\n')\n",
    "    for line in lines[2:-5]:\n",
    "        row = {}\n",
    "        row_data = line.split('      ')\n",
    "        row['label_id'] = row_data[1].strip()\n",
    "        row['precision'] = float(row_data[2])\n",
    "        row['recall'] = float(row_data[3])\n",
    "        row['f1_score'] = float(row_data[4])\n",
    "        row['support'] = float(row_data[5])\n",
    "        report_data.append(row)\n",
    "    df = pd.DataFrame.from_dict(report_data)\n",
    "    return df\n",
    "\n",
    "resultdata = classification_report_csv(result)\n",
    "resultdata['label_id'] = resultdata['label_id'].apply(lambda x: int(x))\n",
    "labels_map['label_id'] = labels_map['label_id'].apply(lambda x: int(x))\n",
    "result_report = pd.merge(resultdata, labels_map, on='label_id', how='left')\n",
    "result_report = result_report[['label', 'label_id', 'precision', 'recall', 'f1_score', 'support']]\n",
    "print(result_report)\n",
    "result_report.to_excel('./checkpoints/classification_report.xlsx', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ab29a055-4f40-4d66-9bbe-4d6e8367a250",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {}\n",
    "for i in range(labels_map.shape[0]):\n",
    "    labels_dict[str(labels_map.loc[i,'label_id'])] = labels_map.loc[i,'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2f22daa7-3032-4ab6-9121-b25559857fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': '体育',\n",
       " '1': '娱乐',\n",
       " '2': '家居',\n",
       " '3': '房产',\n",
       " '4': '教育',\n",
       " '5': '时尚',\n",
       " '6': '时政',\n",
       " '7': '游戏',\n",
       " '8': '科技',\n",
       " '9': '财经'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c446f82a-ff31-4ee3-9d79-bd6c7ea7d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"config class\"\"\"\n",
    "class Config(object):\n",
    "    def __init__(self):\n",
    "        self.model_file = './checkpoints/job_fine_tuned_bert.bin'\n",
    "        self.bert_file = './pretrained_models/chinese_wwm_ext_pytorch/'\n",
    "        self.MAX_SEQ_LEN = 50\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    def json_read(self):\n",
    "        with open(self.jsonfile, 'r', encoding='utf-8') as f:\n",
    "            dicdata = json.load(f)\n",
    "        return dicdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0a75bcf6-a8b0-4564-961c-af6c1bc33a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPrecessForSingleSentence(object):\n",
    "    \"\"\"\n",
    "    对文本进行处理\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, bert_tokenizer, max_workers=10):\n",
    "        \"\"\"\n",
    "        bert_tokenizer :分词器\n",
    "        dataset        :包含列名为'text'与'label'的pandas dataframe\n",
    "        \"\"\"\n",
    "        self.bert_tokenizer = bert_tokenizer\n",
    "        # 创建多线程池\n",
    "        self.pool = ThreadPoolExecutor(max_workers=max_workers)\n",
    "        # 获取文本与标签\n",
    "\n",
    "    def get_input(self, dataset, max_seq_len=30):\n",
    "        sentences = dataset.iloc[:, 0].tolist()\n",
    "        labels = dataset.iloc[:, 1].tolist()\n",
    "        # 切词\n",
    "        tokens_seq = list(\n",
    "            self.pool.map(self.bert_tokenizer.tokenize, sentences))\n",
    "        # 获取定长序列及其mask\n",
    "        result = list(\n",
    "            self.pool.map(self.trunate_and_pad, tokens_seq,\n",
    "                          [max_seq_len] * len(tokens_seq)))\n",
    "        seqs = [i[0] for i in result]\n",
    "        seq_masks = [i[1] for i in result]\n",
    "        seq_segments = [i[2] for i in result]\n",
    "        return seqs, seq_masks, seq_segments, labels\n",
    "\n",
    "    def trunate_and_pad(self, seq, max_seq_len):\n",
    "        # 对超长序列进行截断\n",
    "        if len(seq) > (max_seq_len - 2):\n",
    "            seq = seq[0:(max_seq_len - 2)]\n",
    "        # 分别在首尾拼接特殊符号\n",
    "        seq = ['[CLS]'] + seq + ['[SEP]']\n",
    "        # ID化\n",
    "        seq = self.bert_tokenizer.convert_tokens_to_ids(seq)\n",
    "        # 根据max_seq_len与seq的长度产生填充序列\n",
    "        padding = [0] * (max_seq_len - len(seq))\n",
    "        # 创建seq_mask\n",
    "        seq_mask = [1] * len(seq) + padding\n",
    "        # 创建seq_segment\n",
    "        seq_segment = [0] * len(seq) + padding\n",
    "        # 对seq拼接填充序列\n",
    "        seq += padding\n",
    "        assert len(seq) == max_seq_len\n",
    "        assert len(seq_mask) == max_seq_len\n",
    "        assert len(seq_segment) == max_seq_len\n",
    "        return seq, seq_mask, seq_segment\n",
    "\n",
    "    def single_sent_input(self, sent, device, max_len):\n",
    "        token_seq = bert_tokenizer.tokenize(sent)\n",
    "        test_seq, test_seq_mask, test_seq_segment = self.trunate_and_pad(seq=token_seq, max_seq_len=max_len)\n",
    "        test_seq = torch.tensor([list(test_seq)], dtype=torch.long).to(device)\n",
    "        test_seq_mask = torch.tensor([list(test_seq_mask)], dtype=torch.long).to(device)\n",
    "        test_seq_segment = torch.tensor([list(test_seq_segment)], dtype=torch.long).to(device)\n",
    "        return test_seq, test_seq_mask, test_seq_segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dfb09df6-61a3-445f-91cf-2842c3cde125",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassifier(Config):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def predict(self, text, dicdata, processor, model):\n",
    "        test_seq, test_seq_mask, test_seq_segment = processor.single_sent_input(\n",
    "            sent=text, device=self.device, max_len=self.MAX_SEQ_LEN)\n",
    "        logits = model(test_seq, test_seq_mask, test_seq_segment, labels=None)\n",
    "        logits = logits.softmax(dim=1).argmax(dim=1)\n",
    "        pred_id = logits.detach().cpu().numpy()[0]\n",
    "        result = dicdata[str(pred_id)]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "93b457b1-d382-4b3b-99a2-1f08c58940b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_data = Config()\n",
    "device = config_data.device\n",
    "bert_file = config_data.bert_file\n",
    "finetune_file = config_data.model_file\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(bert_file, do_lower_case=False)\n",
    "processor = DataPrecessForSingleSentence(bert_tokenizer)\n",
    "model = torch.load(open(finetune_file, \"rb\"), map_location='cpu')\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6e99bf75-96fb-4181-bdfb-860a4e58c397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'体育'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#预测\n",
    "text_clf = TextClassifier()\n",
    "text_clf.predict(\"中国乒乓在中国体育中大放光彩\", labels_dict, processor, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362161bb-5f16-49df-a602-4bbb985da545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
